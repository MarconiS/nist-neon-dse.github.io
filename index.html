<!DOCTYPE html>
<html>
	<head>
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<title>NIST DSE Plant Identification with Neon Remote Sensing Data</title>
		<link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
	</head>

	<body>
		<nav class="navbar navbar-inverse navbar-fixed-top">
      		<div class="container">
        		<div class="navbar-header">
          			<button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            			<span class="sr-only">Toggle navigation</span>
            			<span class="icon-bar"></span>
            			<span class="icon-bar"></span>
            			<span class="icon-bar"></span>
          			</button>
          			<a class="navbar-brand" href="/" style='color:white'>NIST DSE Plant Identification with Neon Remote Sensing Data</a>
        		</div>
        		<div id="navbar" class="navbar-collapse collapse">
        			<div class="navbar-right">	
           				<!--button type="submit" class="btn btn-success" style="margin-top:10%">Register</button-->
           			</div>
        		</div>
      		</div>
   	 	</nav>
   	 	<div class='container'>
   	 		<div class='jumbotron'>
   	 			<h1>NIST DSE Plant Identification with Neon Remote Sensing Data</h1>
 				<p class='lead'>
					
				</p>
				<p>
        			<a class="btn btn-lg btn-success" href="register.html" role="button">Register</a>
        		</p>
   	 		</div>

   	 		<div class='container summary'>
				<h2>Introduction</h2>
				<br/>
				<p>
					Understanding ecological patterns and processes across geographical
					scales is crucial to understanding the effects of environmental change
					on natural systems and human society. This Data Science Challenge
					defines the tasks for NIST DSE Plant Identification with Neon Remote
					Sensing Data. We solicit open participations from University, Research
					institute teams as well as individuals, to use Data Science and
					data-driven techniques to help solving ecological and environmental
					problem at continental scale.  
				</p>
				<p>
					This Data Science Challenge and Evaluation is sponsored by the National
					Institute of Standards and Technology (NIST) Data Science Evaluation
					(DSE) Series Pilot. The data is collected by National Ecological
					Observatory Network (NEON), specifically from the Ordway-Swisher
					Biological Station (OSBS) NEON site. The Data Science Challenge is
					organized by the University of Florida, a collaboration between the
					WeEcology Lab and the Data Science Research lab.
				</p>
   	 			<h2>Problem Statement</h2>
 				<br/>
 				<p>
 					NSF is building the National Ecological Observatory Network (NEON), a platform of over 81 different observatory sites, meant to conduct intensive monitoring across different ecosystems in the United States. NEON data products will range from field sampling, to landscape scale Airborne Observation Platform (AOP) remote sensing data. The volume, velocity, and variety of data generated is so complex and big to require interdisciplinary skills such as ecology, computer science, statistics, and data science to be dealt with. For this reason, we are proposing an applied, multidisciplinary, multi-modal, big data challenge to NIST Data Science Evaluation (DSE) series. We envision that aligning DSE with NEON has the potential to result in developing pioneer interdisciplinary approaches and large gains in knowledge that would not have been possible otherwise. These methods will represent the stepping stone of analyses linking AOP data with field measurements of both forest structure and species composition. In this initial challenge we will focus on data from a single location, the Ordway-Swisher Biological Station (OSBS) in north-central Florida. In subsequent challenges, data from across multiple sites will be used; overlapping species will be used to evaluate task specific model reusability across sites.
				</p>
				<p>
					NEON collects a wide spectra of biological, physical, chemical and ecological data. It centrally processes them to derive standard quality data products. NEON provides over 120 high level data products (apart from hundreds of low-level data) along with associated metadata, designs, data collection and data processing documentation. AOP data include remote sensing hyperspectral raster images, LiDAR point clouds, and high resolution color images. This kind of data has been traditionally used for ecosystem structure and species classification. For this big data challenge, we propose to use data science techniques to identify forest structure and species classification. 
				</p>
				<p>
					For this pilot we focus on three tasks:
				</p>
			</div>

			<div class='container tasks'>
				<br/>
				<p>
					<ul class='h4'>
						<li><a href='#task1'>Individual Tree Crown Delineation</a></li>
						<li><a href='#task2'>Crown Alignment</a></li>
						<li><a href='#task3'>Species Classification</a></li>
					</ul>
				</p>
			</div>

			<div class='container task1' id='task1'>
				<br/> <br/>
				<h2>Individual Tree Crown Delineation</h2>
				<br/>
				<p>
					The first step in species identification is determining the boundaries of each individual's crown. Knowing crowns perimeter is fundamental to group pixels assumed to share a similar spectral behavior, address intra/inter individual variability, and facilitate species identification.  Once an individual is attributed to its species (Classification task), it could be possible to investigate a whole range of ecological questions such as communities structuring, biodiversity, biomass and macronutrients cycling. Hyperspectral, LiDAR and high resolution RGB photographs can be used to determine the boundaries of each crown using segmentation algorithms such as graph cuts. However, this task is not trivial, especially for those situations where the canopy is close, crowns may be overlapping, and the spectral signature difference between boundary pixels is smoother. In such a situation, crown delineation may easily end up in producing a different number of crowns than observed on the ground, and/or underestimate some crown's perimeter in favor to their neighbors. In such a situation, also LiDAR data can erroneously estimate individual point heights in the cloud, due to inconsistencies in the GPS signal.
				</p>
				<p>
					Participants in the pilot will be asked to correctly locate and delineate individual crowns for the provided area. We will provide aligned Field data, AOP LiDAR, RGB, and hyperspectral images, plus a sample of ITC data to train the model. The algorithm will produce an .shp file representing the mosaic of each individual's crown area, with pixel resolution of 0.25 x 0.25 m.  
				</p>
				<br/>
				<img src="http://www.mdpi.com/remotesensing/remotesensing-05-06461/article_deploy/html/images/remotesensing-05-06461f5-1024.png" class="img-responsive img-rounded center-block" style='width:30%' alt="Responsive image">
			</div>


			<div class='container task2' id='task2'>
				<br/> <br/>
				<h2>Crown Alignment</h2>
				<br/>
				<p>
					To guarantee good results in scaling up ecological patterns from field to remote sensing, NEON scientists are focusing on aligning different data sources. This process is however tricky, and state of the art products show un-trivial and non-negligible misalignments that need to be taken care of. Airborne data georeferencing and orthorectification occurs using equipment calibrated and mounted on the airplane, making use of a combination of data including LiDAR tilt angle of the pulse, plane GPS coordinates, speed of light, and Inertial Measurement Unit (IMU) coordinates (heading, pitch and roll). Field data, on the other hand, are georeferenced using a hand-held GPS. This process is prone to errors due to limited landmark capabilities and no-line-of-sight, especially when dense vegetation exacerbates GPS signals and accuracy. As a consequence, pixels supposed to be aligned between the two product families, can show offsets greater than 5m. Such offsets may produce mismatching individual stem characteristics or ground measured spectra, compromising the quality of the following two tasks. 
				</p>
				<p>
					Participants in the pilot will be asked to correct field-airborne data misalignment, by using NEON vegetation field data, AOP remote sensing, and a subset of ITC data. 
					In summary:
					Input: NEON vegetation field GPS tree locations, individual IDs, stem and crown diameters, hyperspectral, LiDAR, and a subset of ITC data.
					Output: stem id, center position, latitude and longitude offset, for all ITC data not provided for training.
				</p>
				<br/>
				<img src="http://www.mdpi.com/remotesensing/remotesensing-05-06461/article_deploy/html/images/remotesensing-05-06461f5-1024.png" class="img-responsive img-rounded center-block" style='width:30%' alt="Responsive image">
			</div>

			<div class='container task3' id='task3'>
				<br/> <br/>
				<h2>Species Classification</h2>
				<br/>
				<p>
					Using AOP airborne data and field measurements, determine the species of each tree in the area covered by AOP images themselves. Individual spectral signature will be provided only for a limited number of individuals (NEON ASD files), potentially not for each species in the area. Hence, participants will have to recognize species specific reflectance signature by analyzing patterns of crowns known to be of that particular species. The use of external spectral information recollected in literature will be allowed, as long as it is publicly available. Participants will develop classification algorithms whose output will be an array containing the probability that the ith specific individual belongs to the jth species. We will expect a vector of probabilities for each crown, hence pixel specific classification will be upscaled to the crown object they belong to, and may be used to evaluate the degree of uncertainty linked to the classification.
				</p>
				<br/>
				<img src="https://www.researchgate.net/profile/Christian_Ginzler/publication/228689429/figure/fig2/AS:340868130197522@1458280703761/Figure-3-Tree-species-classification-maps-based-on-imagery-from-May-2007-top-July.jpg" class="img-responsive img-rounded center-block" style='width:30%' alt="Responsive image">
			</div>

			<!--div class='container rules'>
				<h2>Rules</h2>
				<br/>
				<p>
					<ul>
						<li>Code must be Free Open Source Software (FOSS) i.e. No Tools</li>
						<li>No. of Submissions will be limited to 2 / week</li>
						<li>One account per team</li>
						<li>No Merging of teams after the fact</li>
						<li>No limits on team size</li>
						<li>Decision of UF/NIST is final</li>
					</ul>
				</p>
			</div-->

			<div class="jumbotron">
        		<h1>Register !</h1>
        		<p class="lead">
    				Register your intent to compete and we will let you know more details as soon as they are available! 
        		</p>
        		<p>
        			<a class="btn btn-lg btn-success" href="register.html" role="button">Register</a>
        		</p>
      		</div>
   	 	</div>

   	 	<div class='container-fluid footer'>
				<div class='center-block'>
					<p class='h4'>
						&copy; University of Florida 2017
					</p>
				</div>
		</div>

		<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
		<style>
			body { padding-top: 40px; }

			@media screen and (max-width: 768px) {
    			body { padding-top: 0px; }
			}

			.jumbotron {
  				text-align: center;
  				background-color: transparent;
			}

			.jumbotron .btn {
  				padding: 14px 24px;
  				font-size: 21px;
			}

			.footer{
				background-color: black;
				color:white;
				padding-left: 45%;
			}
		</style>
	</body>
</html>
